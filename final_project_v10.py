# -*- coding: utf-8 -*-
"""final_project_v10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KTX9J171myUB4EPLbPhZQKX2VZTTjRBz
"""

import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from keras.models import Sequential, Model
from keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Bidirectional, Input, Dropout, LayerNormalization, MultiHeadAttention
from sklearn.metrics import mean_squared_error

# Download and preprocess stock data
stock_data = yf.download('DAC', start='2014-02-21', end='2024-02-21')
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(stock_data['Close'].values.reshape(-1, 1))

def create_dataset(data, time_step):
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

time_step = 100
X, y = create_dataset(scaled_data, time_step)
train_size = 0.8
X_train, X_test = X[:int(X.shape[0] * train_size)], X[int(X.shape[0] * train_size):]
y_train, y_test = y[:int(y.shape[0] * train_size)], y[int(y.shape[0] * train_size):]

model = Sequential()
model.add(LSTM(units=64, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(units=64))
model.add(Dense(units=64))
model.add(Dense(units=1))
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=10, batch_size=64)

test_loss = model.evaluate(X_test, y_test)
print('Test Loss:', test_loss)

predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)

original_data = stock_data['Close'].values
predicted_data = np.empty_like(original_data)
predicted_data[:] = np.nan
predicted_data[-len(predictions):] = predictions.reshape(-1)

plt.plot(original_data, label='Original Data')
plt.plot(predicted_data, label='Predicted Data')
plt.legend()
plt.show()

new_predictions = model.predict(X_test[-90:])
new_predictions = scaler.inverse_transform(new_predictions)

predicted_data = np.append(predicted_data, new_predictions)
predicted_data[-90:]

plt.plot(original_data, label='Original Data')
plt.plot(predicted_data, label='Predicted Data')
plt.legend()
plt.show()

# CNN with LSTM
cnn_lstm_model = Sequential()
cnn_lstm_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(time_step, 1)))
cnn_lstm_model.add(MaxPooling1D(pool_size=2))
cnn_lstm_model.add(LSTM(units=64))
cnn_lstm_model.add(Dense(units=64, activation='relu'))
cnn_lstm_model.add(Dense(units=1))
cnn_lstm_model.compile(optimizer='adam', loss='mean_squared_error')
cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=64)

# Bidirectional LSTM
bidirectional_lstm_model = Sequential()
bidirectional_lstm_model.add(Bidirectional(LSTM(units=64, return_sequences=True), input_shape=(time_step, 1)))
bidirectional_lstm_model.add(Bidirectional(LSTM(units=64)))
bidirectional_lstm_model.add(Dense(units=64, activation='relu'))
bidirectional_lstm_model.add(Dense(units=1))
bidirectional_lstm_model.compile(optimizer='adam', loss='mean_squared_error')
bidirectional_lstm_model.fit(X_train, y_train, epochs=10, batch_size=64)

# Transformer Model
def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
    x = LayerNormalization(epsilon=1e-6)(inputs)
    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)
    x = Dropout(dropout)(x)
    res = x + inputs

    x = LayerNormalization(epsilon=1e-6)(res)
    x = Dense(ff_dim, activation="relu")(x)
    x = Dropout(dropout)(x)
    x = Dense(inputs.shape[-1])(x)
    return x + res

input_layer = Input(shape=(time_step, 1))
x = transformer_encoder(input_layer, head_size=256, num_heads=4, ff_dim=4, dropout=0.1)
x = Dense(units=64, activation='relu')(x)
x = Dense(units=1)(x)
transformer_model = Model(inputs=input_layer, outputs=x)
transformer_model.compile(optimizer='adam', loss='mean_squared_error')
transformer_model.fit(X_train, y_train, epochs=10, batch_size=64)

# Predictions
cnn_lstm_predictions = cnn_lstm_model.predict(X_test).flatten()
bidirectional_lstm_predictions = bidirectional_lstm_model.predict(X_test).flatten()
transformer_predictions = transformer_model.predict(X_test).flatten()

plt.figure(figsize=(15, 10))

plt.subplot(3, 1, 1)
plt.plot(y_test, color='blue', label='Actual Stock Price')
plt.plot(cnn_lstm_predictions, color='red', label='Predicted Stock Price - CNN with LSTM')
plt.title('CNN with LSTM Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()


plt.subplot(3, 1, 2)
plt.plot(y_test, color='blue', label='Actual Stock Price')
plt.plot(bidirectional_lstm_predictions, color='red', label='Predicted Stock Price - Bidirectional LSTM')
plt.title('Bidirectional LSTM Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()

plt.subplot(3, 1, 3)
plt.plot(original_data, color='blue', label='Actual Stock Price')
plt.plot(predicted_data, color='red', label='Predicted Stock Price - Transformer')
plt.title('Transformer Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.show()

plt.tight_layout()
plt.show()

# Calculate Mean Squared Error
cnn_lstm_mse = mean_squared_error(y_test, cnn_lstm_predictions)
bidirectional_lstm_mse = mean_squared_error(y_test, bidirectional_lstm_predictions)

# Print the MSE for each model
print(f'CNN with LSTM MSE: {cnn_lstm_mse}')
print(f'Bidirectional LSTM MSE: {bidirectional_lstm_mse}')

# Create a comparison table
data = {'Model': ['CNN with LSTM', 'Bidirectional LSTM'],
        'MSE': [cnn_lstm_mse, bidirectional_lstm_mse ]}
comparison_df = pd.DataFrame(data)
print(comparison_df)

# Compute RMSE
cnn_lstm_rmse = np.sqrt(cnn_lstm_mse)
bidirectional_lstm_rmse = np.sqrt(bidirectional_lstm_mse)

# Example mean stock price
mean_stock_price = np.mean(y_test)

# Relative Error
cnn_lstm_relative_error = cnn_lstm_rmse / mean_stock_price
bidirectional_lstm_relative_error = bidirectional_lstm_rmse / mean_stock_price

print(f'CNN with LSTM Relative Error: {cnn_lstm_relative_error}')
print(f'Bidirectional LSTM Relative Error: {bidirectional_lstm_relative_error}')

# Predictions
cnn_lstm_predictions = cnn_lstm_model.predict(X_test).flatten()
bidirectional_lstm_predictions = bidirectional_lstm_model.predict(X_test).flatten()
transformer_predictions = transformer_model.predict(X_test).flatten()

# MSE
cnn_lstm_mse = mean_squared_error(y_test, cnn_lstm_predictions)
bidirectional_lstm_mse = mean_squared_error(y_test, bidirectional_lstm_predictions)

# RMSE
cnn_lstm_rmse = np.sqrt(cnn_lstm_mse)
bidirectional_lstm_rmse = np.sqrt(bidirectional_lstm_mse)

# Relative Error
mean_stock_price = np.mean(y_test)
cnn_lstm_relative_error = cnn_lstm_rmse / mean_stock_price
bidirectional_lstm_relative_error = bidirectional_lstm_rmse / mean_stock_price

# Print results
print(f'CNN with LSTM MSE: {cnn_lstm_mse}, RMSE: {cnn_lstm_rmse}, Relative Error: {cnn_lstm_relative_error}')
print(f'Bidirectional LSTM MSE: {bidirectional_lstm_mse}, RMSE: {bidirectional_lstm_rmse}, Relative Error: {bidirectional_lstm_relative_error}')









